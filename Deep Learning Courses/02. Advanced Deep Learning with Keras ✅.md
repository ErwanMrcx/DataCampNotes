**Table of Contents**

- [[#1. The Keras Functional API|1. The Keras Functional API]]
- [[#2. Two Input Networks Using Categorical Embeddings, Shared Layers, and Merge Layers|2. Two Input Networks Using Categorical Embeddings, Shared Layers, and Merge Layers]]
	- [[#2. Two Input Networks Using Categorical Embeddings, Shared Layers, and Merge Layers#2.1. Category embeddings|2.1. Category embeddings]]
	- [[#2. Two Input Networks Using Categorical Embeddings, Shared Layers, and Merge Layers#2.2. Shared Layers|2.2. Shared Layers]]
	- [[#2. Two Input Networks Using Categorical Embeddings, Shared Layers, and Merge Layers#2.3. Merge Layers|2.3. Merge Layers]]
	- [[#2. Two Input Networks Using Categorical Embeddings, Shared Layers, and Merge Layers#2.4. Fitting and Predicting from multiple inputs|2.4. Fitting and Predicting from multiple inputs]]
- [[#3. 3 input models|3. 3 input models]]


# 1. The Keras Functional API

recap de ce cours: [[01. Introduction to Deep learning with Python ✅]]

```python
# Input/dense/output layers 
from tensorflow.keras.layers import Input, Dense

input_tensor = Input(shape=(1,))
output_tensor = Dense(1)(input_tensor)

# Build the model
from tensorflow.keras.models import Model
model = Model(input_tensor, output_tensor)
```

# 2. Two Input Networks Using Categorical Embeddings, Shared Layers, and Merge Layers

## 2.1. Category embeddings
- Only available in deep learning 
- Advanced type of layers 
- Utile pour les données avec beaucoup de catégorie

To create a embedding Layer
```python
from tensorflow.keras.layers import Embedding

input_tensor = Input(Shape=(1,))
n_teams = 10887
embed_layer = Embedding(tinput_dim=n_teams, input_lenght=1, output_dim=1, name='Team_strenght_lookup')

enbed_tensor = embed_layer(input_tensor)
```

la couche d'intégration créer plusieurs dimensions, ici nous avons besoin de l'aplatir pour pouvoir le mettre en 2D (lignes et colonnes)

```python
from tensorflow.keras.layers import Flatten
flatten_tensor = Flatten()(embed_tensor)
```

```python
# Imports
from tensorflow.keras.layers import Input, Embedding, Flatten
from tensorflow.keras.models import Model

# Create an input layer for the team ID
teamid_in = Input(shape=(1,))

# Lookup the input in the team strength embedding layer
strength_lookup = team_lookup(teamid_in)

# Flatten the output
strength_lookup_flat = Flatten()(strength_lookup)

# Combine the operations into a single, re-usable model
team_strength_model = Model(teamid_in, strength_lookup_flat, name='Team-Strength-Model')
```

## 2.2. Shared Layers

Ici, nous allons créer une même couche d'integration pour les 2 inputs. Nous devons utilisé une couche partagée.

Les couches partagées dans Keras servent à réutiliser les mêmes couches dans différents emplacements d'un modèle. Elles permettent de partager les poids et les biais d'une couche entre plusieurs instances de cette couche.

Cela peut être utile lorsque vous avez besoin d'appliquer une même opération à différentes parties de votre modèle. Par exemple, si vous avez un réseau de neurones convolutif avec plusieurs branches, vous pouvez partager une couche de convolution entre ces branches pour extraire des caractéristiques communes.

```python
shared_layer = Dense (1)
output_tensor_1 = shared_layer (input_tensor_1)
output_tensor_2 = shared_layer (input_tensor_2)
```

![[Pasted image 20230824103239.png]]
## 2.3. Merge Layers

Allow us to combine layers to have a single output. There are multiple merge layer:
• Add
• Subtract
• Multiply
• Concatenatex

```python
from tensorflow.keras.layers import Input, Add
in_tensor_1 = Input ((1,))
in_tensor_2 = Input ((1,))
out_tensor = Add () ([in_tensor_1, in_tensor_21])

from tensorflow.keras.models import Model
model = Model (Lin_tensor_1, in_tensor_2], out_tensor)

model.compile (optimizer='adam', loss='mean_absolute_error')
```

![[Pasted image 20230824112704.png]]

## 2.4. Fitting and Predicting from multiple inputs

To fit a model with multiple input, we have to feed it with a list of inputs:
```python
model.fit([data_1, data_2], target)
model.predict([np.array([[1]]), np.array([[21])])
# output: array ([[3.J], type=float32)
```

**Example**
```python
# Get the team_1 column from the regular season data
input_1 = games_season['team_1']

# Get the team_2 column from the regular season data
input_2 = games_season['team_2']

# Fit the model to input 1 and 2, using score diff as a target
model.fit([input_1,input_2],games_season['score_diff'],epochs=1,batch_size=2048,validation_split=0.10,verbose=True)
```

# 3. 3 and beyond inputs models

```python
from tensorflow.keras. layers import Input, Concatenate, Dense
in_tensor_1 = Input (shape=(1,))
in_tensor_2 = Input (shape= (1,))
in_tensor_3 = Input (shape= (1,))

# Note that we can also use add, or substract
out_tensor= Concatenate () ([in_tensor_1, in_tensor_2, in_tensor_3])
output_tensor = Dense(1) (out_tensor)
```

**Dans le code ci dessous, nous créons un noeud avec Dense(1), nous lui associons 2 input layer. 
output = merge des layer et création d'un noeud et association des précédents tensor.**
```python
shared_layer = Dense (1)
shared_tensor_1 = shared_layer (in_tensor_1)
shared_tensor_2 = shared_layer (in_tensor_1)
out_tensor = Concatenate ()([shared_tensor_1, shared_tensor_2, in_tensor_3])
out_tensor = Dense (1) (out_tensor)
```

![[Pasted image 20230824115920.png]]

**Fitting a 3 input model**
```python
from tensorflow.keras.models import Model

model = Model([in_tensor_1, in_tensor_2, in_tensor_3], out_tensor)
model. compile (loss='mae', optimizer='adam')

model.fit([[train['col1'], train['col2'], train['col3']],
train_data['target'])

model. evalvate ([[test['coll'), test['col2'], test['col3'1],
test['target'])
```

## Summarizing and plotting models 
```python
# Describe the model
model.summary()

# Imports
import matplotlib.pyplot as plt
from tensorflow.keras.utils import plot_model

# Plot the model
plot_model(model, to_file='model.png')

# Display the image
data = plt.imread('model.png')
plt.imshow(data)
plt.show()
```

## Stacking models 

**Using the prediction of one model to predict another one.**
![[Pasted image 20230824143927.png]]

# 2 outputs models

Only deep learning is able to provide several output:
```python
from tensorflow.keras. layers import Input, Concatenate, I
input_tensor = Input (shape= (1,))
output_tensor = Dense (2) (input tensor)

# Inspecting a 2 output model
model.get_weights()
```

## Make a regressor/classifier model 

```python
from tensorflow.keras.layers import Input, Dense

# Build a simple regressor/classifier
input_tensor = Input (shape= (1, ))
output_tensor_reg = Dense (1) (input_tensor)
output_tensor_class = Dense (1, activation='sigmoid')(output_tensor_reg)

from tensorflow.keras.models import Model

# Compile the combinaison classifier/regressor
model = Model (input_tensor, [output_tensor_reg, output_tensor_class])
model.compile (loss=['mean_absolute_error', 'binary_crossentropy'],
optimizer='adam')

# Fit the cl/rg
X = games_tourney_train[ ['seed_diff']]
y_reg = games_tourney_train[['score_diff']]
y_class = games_tourney_train[['won']]
model. fit (X, [y_reg, y-class], epochs=100)

model.get_weights()
# output: 
# [array ([[1.2371823]], type=float32),
# array ([-0.05451894], dtype=float32),
# array ([[O.13870609]], dtype=float32),
# array ([0.00734114], type=float32)]

# Print the approximate win probability of a predicted close game
print(sigmoid(1 * weight))
```

So far...
• Functional API
• Shared layers
• Categorical embeddings
• Multiple inputs
• Multiple outputs
• Regression / Classification in one model 


