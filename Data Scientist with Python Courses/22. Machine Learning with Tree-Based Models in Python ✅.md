# Chapter - 01 : Classification and Regression Trees

Classification and Regression Trees (CART) are powerful algorithms used for solving classification and regression problems. A decision tree is a graphical representation of a set of rules that can be used to make decisions or predictions. 

Classification and regression problems are like trying to solve puzzles. The computer is given some clues or information about the puzzle pieces, like colors or sizes, and it has to figure out what the final picture looks like. Sometimes the puzzles are easy to solve, but sometimes they are really hard and the computer needs extra help. Classification and regression algorithms are like the extra help that the computer gets to solve the puzzle. They help the computer make better, more accurate guesses about what the final picture looks like.

Example:
Suppose we have a dataset of fruits with features like color, size, and shape, and we want to classify them as either "apple" or "orange." A decision tree for this problem would have nodes representing different features (e.g., color, size) and branches representing different possible values for those features (e.g., red, green for color). By following the decision path down the tree, we can classify a fruit as an apple or an orange based on its features.

### Train your first classification tree

```python
# Import DecisionTreeClassifier from sklearn.tree
from sklearn.tree import DecisionTreeClassifier

# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6
dt = DecisionTreeClassifier(max_depth=6, random_state=1)

# Fit dt to the training set
dt.fit(X_train, y_train)

# Predict test set labels
y_pred = dt.predict(X_test)
print(y_pred[0:5])
```

### Evaluate the classification tree

```python
# Import accuracy_score
from sklearn.metrics import accuracy_score

# Predict test set labels
y_pred = dt.predict(X_test)

# Compute test set accuracy
acc = accuracy_score(y_test, y_pred)
print("Test set accuracy: {:.2f}".format(acc))
# 0.88
```

### Logistic regression vs classification tree

A classification tree divides the feature space into rectangular regions. In contrast, a linear model such as logistic regression produces only a single linear decision boundary dividing the feature space into two decision regions.

We have written a custom function called plot_labeled_decision_regions() that you can use to plot the decision regions of a list containing two trained classifiers. You can type help(plot_labeled_decision_regions) in the IPython shell to learn more about this function.

```python
# Import LogisticRegression from sklearn.linear_model
from sklearn.linear_model import  LogisticRegression

# Instatiate logreg
logreg = LogisticRegression(random_state=1)

# Fit logreg to the training set
logreg.fit(X_train, y_train)

# Define a list called clfs containing the two classifiers logreg and dt
clfs = [logreg, dt]

# Review the decision regions of the two classifiers
plot_labeled_decision_regions(X_test, y_test, clfs)
```

### Classification tree Learning

```python
# Import DecisionTreeClassifier from sklearn.tree
from sklearn.tree import DecisionTreeClassifier

# Instantiate dt_entropy, set 'entropy' as the information criterion
dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)

# Fit dt_entropy to the training set
dt_entropy.fit(X_train, y_train)

```

### Entropy vs Gini index

Entropy and Gini index are two different methods for measuring the impurity of a decision tree node. Entropy measures the unpredictability of the data, while Gini index measures the probability of misclassifying a randomly chosen element if it were randomly labeled according to the distribution of labels in the node.

```python
# Import accuracy_score from sklearn.metrics
from sklearn.metrics import accuracy_score

# Use dt_entropy to predict test set labels
y_pred= dt_entropy.predict(X_test)

# Evaluate accuracy_entropy
accuracy_entropy = accuracy_score(y_test, y_pred)

# Print accuracy_entropy
print(f'Accuracy achieved by using entropy: {accuracy_entropy:.3f}')

# Print accuracy_gini
print(f'Accuracy achieved by using the gini index: {accuracy_gini:.3f}')

```

### Decision tree for regression

```python
# Import DecisionTreeRegressor from sklearn.tree
from sklearn.tree import DecisionTreeRegressor

# Instantiate dt
dt = DecisionTreeRegressor(max_depth=8,
             min_samples_leaf=0.13,
            random_state=3)

# Fit dt to the training set
dt.fit(X_train, y_train)
```

### Evaluation

```python
# Import mean_squared_error from sklearn.metrics as MSE
from sklearn.metrics import mean_squared_error as MSE

# Compute y_pred
y_pred = dt.predict(X_test)

# Compute mse_dt
mse_dt = MSE(y_test, y_pred)

# Compute rmse_dt
rmse_dt = mse_dt**(1/2)

# Print rmse_dt
print("Test set RMSE of dt: {:.2f}".format(rmse_dt))

# Predict test set labels
y_pred_lr = lr.predict(X_test)

# Compute mse_lr
mse_lr = MSE(y_test, y_pred_lr)

# Compute rmse_lr
rmse_lr = mse_lr**(1/2)

# Print rmse_lr
print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))

# Print rmse_dt
print('Regression Tree test set RMSE: {:.2f}'.format(rmse_dt))

```

---

# Chapter - 02 : The Bias-Variance Tradeoff

The bias-variance tradeoff is a fundamental concept in machine learning. Bias refers to the error introduced by approximating a real-world problem with a simplified model. Variance, on the other hand, refers to the amount by which the model's prediction varies for different training sets. Finding the right balance between bias and variance is crucial for building accurate models. 

Example:
Consider a regression problem where we are trying to predict house prices. If we use a simple linear model to predict prices, we might have high bias because the model cannot capture complex relationships in the data. However, if we use a highly flexible model like a deep neural network, we might have high variance because the model can overfit the training data. Balancing bias and variance involves selecting a model that performs well on unseen data while avoiding underfitting or overfitting.

### Generalization Error

- Bais
- Variance: how much f is inconsistent over different training sets
- Overfitting: too much noise
- Underfitting: not enough flexible

![Untitled](1.%20Final-Notes/Data%20Science/cours-data-camp/Done/21.%20Machine%20Learning%20with%20tree%20based%20models/21%20Machine%20Learning%20with%20Tree-Based%20Models%20in%20Pyth%203500147efdcd42b496e603ebb734daae/Untitled.png)

The lower Generalization error the better.

### Diagnose bias and variance problems

Better model evaluation with cross-validation

- Test set should not be touched until we are confident about f performance
- Use K-Fold CV or Hold-out CV pour tester les biais ou la variance

```python
# Import train_test_split from sklearn.model_selection
from  sklearn.model_selection import train_test_split

# Set SEED for reproducibility
SEED = 1

# Split the data into 70% train and 30% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)

# Instantiate a DecisionTreeRegressor dt
dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=SEED)

```

### SEED

In Python, you can set the seed using the `random.seed()` function from the `random` module or the `numpy.random.seed()` function from the `numpy` module.

For example, to set the random seed to 1, you can use:

```
import random
random.seed(1)

import numpy as np
np.random.seed(1)

```

This will ensure that the random number generator produces the same sequence of numbers every time the code is executed, which can be useful for reproducibility.

In machine learning, you can set the random seed when instantiating a model or using a function that generates random numbers. For example, in the code snippet in the original post, the random seed is set using the `random_state` parameter when instantiating the `DecisionTreeRegressor` and `BaggingClassifier` models.

```
dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=SEED)
bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)

```

This ensures that the same sequence of random numbers is generated every time the models are trained, resulting in the same model being produced each time.

### Evaluate the 10-fold CV error

Calcul du RMSE → Plus t’es proche de 1, mieux c’est.

```python
# Compute the array containing the 10-folds CV MSEs
MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10,
                       scoring='neg_mean_squared_error',
                       n_jobs=-1)

# Compute the 10-folds CV RMSE
RMSE_CV = (MSE_CV_scores.mean())**(1/2)

# Print RMSE_CV
print('CV RMSE: {:.2f}'.format(RMSE_CV))

```

### Evaluate the training error

```python
# Import mean_squared_error from sklearn.metrics as MSE
from sklearn.metrics import mean_squared_error as MSE

# Fit dt to the training set
dt.fit(X_train, y_train)

# Predict the labels of the training set
y_pred_train = dt.predict(X_train) [[On]] récupère "l'équation du model"

# Evaluate the training set RMSE of dt
RMSE_train = (MSE(y_train, y_pred_train))**(1/2) [[Différence]] entre les y_train et y_pred avec le MSE mis au carré

# Print RMSE_train
print('Train RMSE: {:.2f}'.format(RMSE_train))
```

### Possible issues:

- Overfit : If f suffers from high variance: CV error of f > training set error of f
    - Decrease model complexity (decrease max depth, increase min samples…)
    - More data
- Underfit: f suffers from high bias: CV error of f ~= training set error of f >> desired error
    - Increased model complexity
    - Gather more relevant features

### Voting Classifiers

A voting classifier is like a group of friends who want to make a decision together. Each friend has their own idea or opinion about what the decision should be. They all vote for their idea, and then the decision that gets the most votes wins.

In a voting classifier, we have different machine learning models instead of friends. Each model has its own way of making predictions. They all make their predictions for a given problem, and then the voting classifier counts how many models predict one thing versus another. The prediction that gets the most votes becomes the final prediction of the voting classifier.

![Untitled](1.%20Final-Notes/Data%20Science/cours-data-camp/Done/21.%20Machine%20Learning%20with%20tree%20based%20models/21%20Machine%20Learning%20with%20Tree-Based%20Models%20in%20Pyth%203500147efdcd42b496e603ebb734daae/Untitled%201.png)

(

![Untitled](Untitled%202.png)

![Untitled](Untitled%203.png)

![Untitled](Untitled%204.png)

![Untitled](Untitled%205.png)

### Better performanceL with a Voting Classifier

The Voting Classifier combines the predictions of multiple machine learning models to make a final prediction. By doing so, it reduces the variance of the predictions and can improve the accuracy of the final prediction. In the example provided, the Voting Classifier was able to achieve an accuracy of 76.4%, which isme higher than the accuracy achieved by any individual model.

```python
# Import VotingClassifier from sklearn.ensemble
from sklearn.ensemble import VotingClassifier

# Instantiate a VotingClassifier vc
vc = VotingClassifier(estimators=classifiers)

# Fit vc to the training set
vc.fit(X_train, y_train)

# Evaluate the test set predictions
y_pred = vc.predict(X_test)

# Calculate accuracy score
accuracy = accuracy_score(y_test, y_pred)
print('Voting Classifier: {:.3f}'.format(accuracy))

<script.py> output:
    Voting Classifier: 0.764

```

# Chapter - 03 : Bagging and Random Forests

Bagging (Bootstrap Aggregating) and Random Forests are ensemble techniques that combine multiple decision trees to improve model performance. Bagging involves creating multiple bootstrap samples from the training data and training individual decision trees on each sample. Random Forests take this idea further by adding randomness in the feature selection process. Let's explore an example:

Example:
Suppose we have a dataset of images with labels indicating whether they contain a dog or a cat. To improve classification accuracy, we can use bagging or random forests. Bagging involves creating multiple subsets of the training data by resampling with replacement. Each subset is used to train an individual decision tree. In the end, the predictions from all the trees are combined by majority voting or averaging to make the final prediction. Random Forests add an additional randomness by selecting only a subset of features at each node while building the decision tree, reducing the correlation between the trees.

Bagging = test avec le same algo mais différents subset qui sont créer avec le méthode bootstrap (cad avec replacement)

Bagging for classification:

- Majority of voting

Bagging for regression:

- Aggregates predictions through averaging

```python
# Import DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier

# Import BaggingClassifier
from sklearn.ensemble import BaggingClassifier

# Instantiate dt
dt = DecisionTreeClassifier(random_state=1)

# Instantiate bc
bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)

# Fit bc to the training set
bc.fit(X_train, y_train)

# Predict test set labels
y_pred = bc.predict(X_test)

# Evaluate acc_test
acc_test = accuracy_score(y_test, y_pred)
print('Test set accuracy of bc: {:.2f}'.format(acc_test))

```

### Out of Bag Evaluation

OOB = comme le test split mais pour le bagging, ce qui permet de faire une comparaison entre les subsets test and train.

Bagging:

- Base estimator can be any model: Decision tree, regression, neural network,…
- Each estimator is trained on a distinct boostrap sample of the training set
- Use all features for training and prediction

In sklearn, you can evaluate the OOB accuracy of an ensemble classifier by setting the parameter oob_score to True during instantiation. After training the classifier, the OOB accuracy can be obtained by accessing the .oob_score_ attribute from the corresponding instance.

```python
# Import DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier

# Import BaggingClassifier
from sklearn.ensemble import BaggingClassifier

# Instantiate dt
dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)

# Instantiate bc
bc = BaggingClassifier(base_estimator=dt,
            n_estimators=50,
            oob_score=True,
            random_state=1)

```

OOB Score vs Test Set Score

```python
# Fit bc to the training set
bc.fit(X_train, y_train)

# Predict test set labels
y_pred = bc.predict(X_test)

# Evaluate test set accuracy
acc_test = accuracy_score(y_test, y_pred)

# Evaluate OOB accuracy
acc_oob = bc.oob_score_

# Print acc_test and acc_oob
print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))

```

### Random Forests (RF)

- Base estimator : Decision tree
- Each estimator is trained on diff bootstrap
- RF randomized the features set (d = nurmber of features sampled w/o replacement)

```python
# Import RandomForestRegressor
from sklearn.ensemble import RandomForestRegressor

# Instantiate rf
rf = RandomForestRegressor(n_estimators=25,
            random_state=2)

# Fit rf to the training set
rf.fit(X_train, y_train)

# Import mean_squared_error as MSE
from sklearn.metrics import mean_squared_error as MSE

# Predict the test set labels
y_pred = rf.predict(X_test)

# Evaluate the test set RMSE
rmse_test = MSE(y_test, y_pred)**(1/2)

# Print rmse_test
print('Test set RMSE of rf: {:.2f}'.format(rmse_test))

# Create a pd.Series of features importances
importances = pd.Series(data=rf.feature_importances_,
                        index= X_train.columns)

# Sort importances
importances_sorted = importances.sort_values()

# Draw a horizontal barplot of importances_sorted
importances_sorted.plot(kind='barh', color='lightgreen')
plt.title('Features Importances')
plt.show()

```

---

# Chapter -04 : Boosting

Boosting:
Boosting is another ensemble technique that combines weak learners into a strong learner. It focuses on training models that sequentially correct the mistakes made by previous models. Boosting algorithms assign higher weights to misclassified instances, forcing subsequent models to focus on them. Let's see an example:

Example:
Imagine we have a dataset of emails labeled as spam or not spam. We want to build a boosting model to accurately classify emails. Initially, we train a weak learner, such as a decision stump (a simple decision tree with only one split), on the data. We then assign higher weights to misclassified emails and train another weak learner. This process is repeated iteratively, with subsequent models focusing on the misclassified instances from previous iterations. The final prediction is made by combining the predictions of all the weak learners.

Boosting = method combining weak learners to form a strong learner.

Weak Learner = weak learner = model doing slightly better than random guessing

### Adaboost

- Attribute weight to training instances (alpha)
- alpha depends on the predictor training error
- Learning rate = trade off between eta and number of estimators (balance)

```python
# Import DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier

# Import AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier

# Instantiate dt
dt = DecisionTreeClassifier(max_depth=2, random_state=1)

# Instantiate ada
ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)

# Fit ada to the training set
ada.fit(X_train,y_train)
# Compute the probabilities of obtaining the positive class

y_pred_proba = ada.predict_proba(X_test)[:,1]

# Import roc_auc_score
from sklearn.metrics import roc_auc_score

# Evaluate test-set roc_auc_score
ada_roc_auc = roc_auc_score(y_test, y_pred_proba)

# Print roc_auc_score
print('ROC AUC score: {:.2f}'.format(ada_roc_auc))

```

### Gradient Boosting (GB)

Gradient Boosting (GB) is a machine learning algorithm used for both regression and classification tasks. It builds an ensemble of decision trees, where each subsequent tree aims to correct the errors made by the previous one, by boosting the importance of misclassified samples.

Techniques using:

- Sequential correction of predecessor’s
- Does not tweaks the weights

```python
# Import GradientBoostingRegressor
from sklearn.ensemble import GradientBoostingRegressor

# Instantiate gb
gb = GradientBoostingRegressor(max_depth=4,
            n_estimators=200,
            random_state=2)

# Fit gb to the training set
gb.fit(X_train, y_train)

# Predict test set labels
y_pred = gb.predict(X_test)

# Import mean_squared_error as MSE
from sklearn.metrics import mean_squared_error as MSE

# Compute MSE
mse_test = MSE(y_test, y_pred)

# Compute RMSE
rmse_test = mse_test**(1/2)

# Print RMSE
print('Test set RMSE of gb: {:.3f}'.format(rmse_test))

```

### Stochastic Gradient Boosting (SGB)

Stochastic Gradient Boosting (SGB) is a machine learning algorithm that is used for both regression and classification tasks. It is a type of gradient boosting algorithm that uses random subsets of the training data to improve the performance of the model and reduce overfitting.

- each tree is trained on a random subset
- the sampled instances are sampled without replacement
- features are samples when choosing split points

```python
# Import GradientBoostingRegressor
from sklearn.ensemble import GradientBoostingRegressor

# Instantiate sgbr
sgbr = GradientBoostingRegressor(max_depth=4,
            subsample=0.9,
            max_features=0.75,
            n_estimators=200,
            random_state=2)

# Fit sgbr to the training set
sgbr.fit(X_train,y_train)

# Predict test set labels
y_pred = sgbr.predict(X_test)

# Import mean_squared_error as MSE
from sklearn.metrics import mean_squared_error as MSE

# Compute test set MSE
mse_test = MSE(y_test,y_pred )

# Compute test set RMSE
rmse_test = mse_test**(1/2)

# Print rmse_test
print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))

```

# Model Tuning

Model Tuning (for a 5-year-old):

Model tuning is like adjusting a toy car to make it work better and faster. When we play with the toy car, we can change some parts or settings to make it go faster or turn better.

In machine learning, we have special models called tree-based models that help us make predictions. But sometimes, these models need a little adjustment to work their best.

Hyperparameters are like the special settings of the tree-based models. They control how the models behave. For example, imagine we have a toy car with a special button that can make it go faster or slower. That button is a hyperparameter.

We can change the hyperparameters to make the models better. If we want the models to be more accurate but not too complicated, we can adjust the hyperparameters to make the models simpler. On the other hand, if we want the models to be more detailed and accurate, we can adjust the hyperparameters to make the models more complex.

There are different ways to find the best hyperparameters. One way is called grid search. It's like trying different combinations of settings and seeing which one works best. It's a bit like trying different keys to unlock a treasure chest. Another way is called random search. It's like randomly trying different settings to see if we get lucky and find the best one.

By tuning the models, we can make them more powerful and accurate, just like adjusting a toy car to make it faster and better at racing.

Machine learning model:

- Parameters: learned from data (split point of a node, split feature)
- hyperparameters: not learned from data (max_depth, min_samples_leaf, splitting criterion…)

Problem : search for a set of optimal hypeeparameters for a learning algo

solution: find a set of hyperparameters with optimal model

otpimal model = yield to an optimal score

score : in sklearn = accuracy and r^2

cross val to evaluatue score

Method for hyperparameter tuning:

- grid search

![Untitled](Untitled%206.png)

- random search
- bayesian optimization
- genetic algo

### Tuning a CART's Hyperparameters

```python
# Define params_dt
params_dt = {
        'max_depth': [2, 3, 4],
        'min_samples_leaf': [0.12, 0.14, 0.16,0.18],
      }

# Import GridSearchCV
from sklearn.model_selection import GridSearchCV

# Instantiate grid_dt
grid_dt = GridSearchCV(estimator=dt,
                       param_grid=params_dt,
                       scoring='roc_auc',
                       cv=5,
                       n_jobs=-1)

```

1. Evaluate the optimal tree
In this exercise, you'll evaluate the test set ROC AUC score of grid_dt's optimal model.

In order to do so, you will first determine the probability of obtaining the positive label for each test set observation. You can use the methodpredict_proba() of an sklearn classifier to compute a 2D array containing the probabilities of the negative and positive class-labels respectively along columns.

```python
# Import roc_auc_score from sklearn.metrics
from sklearn.metrics import roc_auc_score

# Extract the best estimator
best_model = grid_dt.best_estimator_

# Predict the test set probabilities of the positive class
y_pred_proba = best_model.predict_proba(X_test)[:,1]

# Compute test_roc_auc
test_roc_auc = roc_auc_score(y_test, y_pred_proba)

# Print test_roc_auc
print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))

```

### Tuning a RF's Hyperparameters

Weight the impact of tuning on the whole project to check if it is worth it.

```python
# Define the dictionary 'params_rf'
params_rf = {
    'n_estimators':[100,350,500],
    'max_features':['log2','auto','sqrt'],
    'min_samples_leaf':[2,10,30]
}

# Import GridSearchCV
from sklearn.model_selection import GridSearchCV

# Instantiate grid_rf
grid_rf = GridSearchCV(estimator=rf,
                       param_grid=params_rf,
                       scoring='neg_mean_squared_error',
                       cv=3,
                       verbose=1,
                       n_jobs=-1)

```

```python
# Import mean_squared_error from sklearn.metrics as MSE
from sklearn.metrics import mean_squared_error as MSE

# Extract the best estimator
best_model = grid_rf.best_estimator_

# Predict test set labels
y_pred = best_model.predict(X_test)

# Compute rmse_test
rmse_test = MSE(y_test, y_pred)**(1/2)

# Print rmse_test
print('Test RMSE of best model: {:.3f}'.format(rmse_test))

```